{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06b38839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import datetime\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import multiprocessing\n",
    "import networkx as nx\n",
    "import scipy as sp\n",
    "from math import floor, ceil\n",
    "from itertools import chain, product, repeat\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm.auto import tqdm, trange\n",
    "import warnings\n",
    "from multiprocessing import Pool\n",
    "from collections import defaultdict\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e720d0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overlaps(inds_1, inds_2): #verified.\n",
    "    \"\"\"\n",
    "    Calculate the overlaps between two reads and the distance spanned by them.\n",
    "    The reads are each assumed to comprise two arms, a left and a right arm.\n",
    "    inds_1 and inds_2: [left start, left stop, right start, right stop]\n",
    "    Returns overlap_l, overlap_r, span_l, span_r: int, int, int, int\n",
    "    \"\"\"\n",
    "    overlap_l = min(inds_1[1], inds_2[1]) - max(inds_1[0], inds_2[0]) + 1\n",
    "    overlap_r = min(inds_1[3], inds_2[3]) - max(inds_1[2], inds_2[2]) + 1\n",
    "    span_l = max(inds_1[1], inds_2[1]) - min(inds_1[0], inds_2[0]) + 1\n",
    "    span_r = max(inds_1[3], inds_2[3]) - min(inds_1[2], inds_2[2]) + 1\n",
    "    return overlap_l, overlap_r, span_l, span_r\n",
    "\n",
    "def get_overlap_ratios(inds_1, inds_2): #verified.\n",
    "    \"\"\"\n",
    "    Function to calculate the overlap ratio between two reads\n",
    "    inds_1 and inds_2: [left start, left stop, right start, right stop]\n",
    "    Returns ratio_l, ratio_r : float, float\n",
    "    The integer divisions are not backward compatible with python2. \n",
    "    \"\"\"\n",
    "    overlap_l, overlap_r, span_l, span_r = get_overlaps(inds_1, inds_2)\n",
    "    ratio_l = overlap_l / span_l; ratio_r = overlap_r / span_r\n",
    "    return ratio_l, ratio_r\n",
    "\n",
    "covlimit = 100\n",
    "def subsample(genealign, covlimit): #requires random. \n",
    "    #genealign: [[alignid,info1,info2]...]. info:chrom,strand,start,end,line\n",
    "    cov={}; nalign=len(genealign)\n",
    "    # get the list of [[chrom, srrabd, start, end] * n]\n",
    "    intvls = [i[1:5] for i in genealign] + [i[6:10] for i in genealign] \n",
    "    # create a dict (chrom, strand, start/end):count\n",
    "    for intvl in intvls:\n",
    "        for i in intvl[2:4]:\n",
    "            if (*intvl[:2],i) not in cov: cov[(*intvl[:2],i)]=1\n",
    "            else: cov[(*intvl[:2],i)]+=1\n",
    "    # the max of start/end repetitive counts\n",
    "    maxcov=max(list(cov.values()))\n",
    "    genealignlimit = genealign #first set the limited list to all alignments\n",
    "    geneextra = [] #store nonselected alignments.\n",
    "    # if max of start/end repetitive counts is greater than the user set limit\n",
    "    # randomly select int(nalign*covlimit/maxcov) entries, exclude then and save in geneextra\n",
    "    if maxcov>covlimit: \n",
    "        random.seed(0)\n",
    "        idx=random.sample(range(nalign),int(nalign*covlimit/maxcov))\n",
    "        geneextra = [genealign[i] for i in range(nalign) if i not in idx]\n",
    "        genealignlimit = [genealign[i] for i in idx]\n",
    "    return genealignlimit, geneextra\n",
    "\n",
    "def graph_align(genealign, t): #requires networkx. only graph the sub sampled\n",
    "    \"\"\"\n",
    "    Function that creates a weighted graph representation of the alignments\n",
    "    Alignments are represented by nodes. Two alignments with left and right\n",
    "    overlap ratios > threshold t are connected by an edge of weight overlap/span\n",
    "    input genealign is one item from the genealigndict dictionary.\n",
    "    (gene1,gene2):[[alignid,info1,info2]...]. info:chrom,strand,start,end,line\n",
    "    alignids: np array. Read IDs\n",
    "    genealign: list of alignments\n",
    "    t: float. Overlap threshold, default 0.1 for cliques and 0.5 for spectral\n",
    "    Returns graph: NetworkX graph\n",
    "    requires networkx, get_overlap_ratios(), etc.\n",
    "    \"\"\"\n",
    "    graph = nx.Graph()\n",
    "    alignids = [i[0] for i in genealign]\n",
    "    alignindsdict = dict([(i[0],i[3:5]+i[8:10]) for i in genealign])\n",
    "    #alignindsdict format: (alignid: [start1, end1, start2, end2])\n",
    "    graph.add_nodes_from(alignids)\n",
    "    # just the [start1, end1, start2, end2] from alignindsdict\n",
    "    aligninds = np.array(list(alignindsdict.values()))\n",
    "    sorted_ids = []\n",
    "    for i in range(4): sorted_ids.append([alignid for (ind, alignid) in\n",
    "                                          sorted(zip(aligninds[:,i],alignids))])\n",
    "    for (id_1, inds_1) in tqdm(zip(alignids, aligninds), total = len(alignids)):\n",
    "        for i in range(4):\n",
    "            id_list = sorted_ids[i]; j = id_list.index(id_1); loop_flag = 1\n",
    "            if i%2 == 0: check_loop = (j < len(aligninds) - 1)\n",
    "            else: check_loop = (j > 0)\n",
    "            while (loop_flag == 1) and check_loop:\n",
    "                if i%2 == 0: j += 1; check_loop = (j < len(aligninds) - 1)\n",
    "                else: j -= 1; check_loop = (j > 0)\n",
    "                id_2 = id_list[j]; inds_2 = alignindsdict[id_2]\n",
    "                if i == 0: check_inds = (inds_2[0] <= inds_1[1])\n",
    "                elif i == 1: check_inds = (inds_2[1] >= inds_1[0])\n",
    "                elif i == 2: check_inds = (inds_2[2] <= inds_1[3])\n",
    "                else: check_inds = (inds_2[3] >= inds_1[2])\n",
    "                if check_inds:\n",
    "                    ratio_l, ratio_r = get_overlap_ratios(inds_1, inds_2)\n",
    "                    if (ratio_l > t) and (ratio_r > t): \n",
    "                         graph.add_edge(id_1, id_2, weight=(ratio_l + ratio_r))\n",
    "                else: loop_flag = 0\n",
    "    return graph\n",
    "\n",
    "def get_spectral(graph, n=10, t=5): \n",
    "    \"\"\"\n",
    "    Function that performs spectral clustering on the weighted graph.\n",
    "    Cluster number, k, is determined by finding the first eigengap that is\n",
    "    some amount t larger than preceding eigengaps.\n",
    "    graph : NetworkX graph. Weighted graph representation of all alignments\n",
    "    n: int. Number of eigenvalues (DG splits) to consider threshold\n",
    "    t: int. Multiplicity of median eigengap threshold\n",
    "    Returns align_dg_dict, dg_ind: dict, int\n",
    "    requires KMeans, networkx functions:\n",
    "    connected_components(),subgraph.nodes(), subgraph.degree(), etc.  \n",
    "    \"\"\"\n",
    "    dg_ind = 0; align_dg_dict = {}\n",
    "    subgraphs = [graph.subgraph(c) for c in nx.connected_components(graph)]\n",
    "    for subgraph in tqdm(subgraphs, total = len(subgraphs)):\n",
    "        k = 1\n",
    "        if len(subgraph) > 1:\n",
    "            L=nx.laplacian_matrix(\n",
    "                subgraph,nodelist=sorted(subgraph.nodes())).todense()\n",
    "            D=np.diag([subgraph.degree[node]\n",
    "                       for node in sorted(subgraph.nodes())])\n",
    "            w, v = sp.linalg.eigh(L, D, type=1)  # Since L always symmetric\n",
    "            eigengaps = np.diff(w[:(n + 1)])\n",
    "            if len(eigengaps) > 2:\n",
    "                if (w[1] > 1) and (w[1] >= 10*np.median(eigengaps[1:])): k = 2\n",
    "                else:\n",
    "                    # ignore divide by 0 warning if eigengaps median is 0\n",
    "                    np.seterr(divide='ignore', invalid='ignore')\n",
    "                    eigenratios = np.copy(eigengaps)\n",
    "                    eigenratios[1:] = np.array([\n",
    "                        eigengaps[i] / np.median(eigengaps[:i])\n",
    "                        for i in range(1, len(eigengaps))])\n",
    "                    if max(eigenratios) >= t: k = np.argmax(eigenratios>=t)+2\n",
    "            Y = np.transpose(v[:k])\n",
    "            kmeans = KMeans(n_clusters=k, random_state=0).fit(Y)\n",
    "            kmeans.labels_ += dg_ind\n",
    "            subgraph_dict = dict(zip(sorted(subgraph.nodes()), kmeans.labels_))\n",
    "        else: subgraph_dict = {list(subgraph)[0]: dg_ind}\n",
    "        align_dg_dict = {**align_dg_dict, **subgraph_dict}; dg_ind += k\n",
    "    return align_dg_dict #asignment of alignment IDs to DG numbers.\n",
    "\n",
    "def get_cliques(graph):\n",
    "    \"\"\"\n",
    "    Function that gets cliques from subgraphs of connected components.\n",
    "    graph : NetworkX graph. Weighted graph representation of all alignments\n",
    "    Returns align_dg_dict : dict, int\n",
    "    requires networkx (<2.4) functions:\n",
    "    connected_components(), subgraph(), find_cliques, etc. \n",
    "    \"\"\"\n",
    "    dg_ind = 0; align_dg_dict = {}\n",
    "    subgraphs = [graph.subgraph(c) for c in nx.connected_components(graph)]\n",
    "    for subgraph in tqdm(subgraphs, total = len(subgraphs)):\n",
    "        if len(subgraph) > 1:\n",
    "            cliques_kept = []\n",
    "            cliques_all = list(nx.find_cliques(subgraph))\n",
    "            cliques_all.sort(key=len)\n",
    "            while len(cliques_all) > 0:\n",
    "                cliques_nodes=set(\n",
    "                    [node for clique in cliques_kept for node in clique])\n",
    "                clique_test = cliques_all.pop()\n",
    "                if not set(list(clique_test)).intersection(cliques_nodes):\n",
    "                    cliques_kept.append(clique_test)\n",
    "            dg_inds=[[dg_ind+i]*len(clique)\n",
    "                     for i,clique in enumerate(cliques_kept)]\n",
    "            subgraph_dict = dict(\n",
    "                zip([node for clique in cliques_kept for node in clique],\n",
    "                    [ind for inds_list in dg_inds for ind in inds_list]))\n",
    "            align_dg_dict = {**align_dg_dict, **subgraph_dict}\n",
    "            dg_ind += len(cliques_kept)\n",
    "        else: read_id=list(subgraph)[0];align_dg_dict[read_id]=dg_ind;dg_ind+=1\n",
    "    return align_dg_dict #asignment of alignment IDs to DG numbers. \n",
    "\n",
    "def get_dgs(align_dg_dict):\n",
    "    \"\"\"\n",
    "    Function that creates inverse dictionary of align_dg_dict\n",
    "    align_dg_dict: dict. Dictionary of alignments and clustering DG assignments\n",
    "    Returns dg_align_dict: dict, k=dg_id, v=[alignids]\n",
    "    align_dg_dict comes from get_spectral(graph) or get_cliques(graph)\n",
    "    \"\"\"\n",
    "    dgs_list = set(align_dg_dict.values()) #list of all duplex groups\n",
    "    dg_align_dict = {}\n",
    "    for dg in tqdm(dgs_list, total = len(dgs_list)):\n",
    "        dg_align_list =[x for (x,y) in align_dg_dict.items() if y == dg]\n",
    "        dg_align_dict[dg] = dg_align_list\n",
    "    return dg_align_dict\n",
    "\n",
    "\n",
    "def filter_dgs(dg_align_dict, genealign):\n",
    "    \"\"\"\n",
    "    Function to filter out invalid DGs\n",
    "    DGs whose alignments are all identical are eliminated.\n",
    "    Here we compare (chr1,strand1,start1,end1,chr2,strand2,start2,end2)\n",
    "    DGs with fewer than two alignments are also eliminated.\n",
    "    genealign, format as follows\n",
    "    (gene1,gene2):[[alignid,info1,info2]...]. info:chrom,strand,start,end,line\n",
    "    dg_align_dict: Dictionary of DGs and their alignments\n",
    "    Returns filtered_dict : dict\n",
    "    \"\"\"\n",
    "    filtered_dict = {}\n",
    "    for (dg, alignids) in tqdm(dg_align_dict.items(), total = len(dg_align_dict)):\n",
    "        num_align = len(alignids)\n",
    "        infolist = [tuple(i[1:5]+i[6:10]) for i in genealign]\n",
    "        if num_align>1 and len(set(infolist))>1: filtered_dict[dg] = alignids\n",
    "    return filtered_dict\n",
    "\n",
    "def create_stats(dg_align_dict, genealign):\n",
    "    \"\"\"\n",
    "    Function that creates the DG stats dictionary\n",
    "    The DG stats dictionary no longer has individual alignments but instead\n",
    "    contains metadata for each DG, including number of alignments, coverage, and\n",
    "    nonoverlapping group (NG). Coverage fraction is defined as c/sqrt(a*b) where\n",
    "        + c = number of alignments in a given DG\n",
    "        + a = number of alignments overlapping the left arm of the DG\n",
    "        + b = number of alignments overlapping the right arm of the DG\n",
    "    dg_align_dict: dict. Dictionary of DGs and their alignments\n",
    "    genealign: list of alignments to this (gene1,gene2) pair\n",
    "    format: [[alignid,info1,info2]...]. info:chrom,strand,start,end,line\n",
    "    Returns dg_stats_dict: dict\n",
    "    \"\"\"\n",
    "    ng_ind = 0\n",
    "    gene_align = list(chain.from_iterable(dg_align_dict.values()))#all alignids\n",
    "    dg_stats_dict = {}; ng_dict = {}\n",
    "    for (dg, alignids) in tqdm(dg_align_dict.items()):\n",
    "        # Get DG indices: dg_min, dg_max and dg_inds (4 medians for each dg)\n",
    "        dg1aligndict = dict.fromkeys(alignids)\n",
    "        dg_min=min([i[3] for i in genealign if i[0] in dg1aligndict])\n",
    "        dg_max=max([i[9] for i in genealign if i[0] in dg1aligndict])\n",
    "        \n",
    "        inds=np.array([i[3:5]+i[8:10]for i in genealign if i[0]in dg1aligndict])\n",
    "        \n",
    "        # change inds from median to min of the start and max of the right\n",
    "        #dg_inds = [np.median(inds[:,0]), np.median(inds[:,1]), np.median(inds[:,2]), np.median(inds[:,3])]\n",
    "        dg_inds = [np.min(inds[:,0]), np.max(inds[:,1]), np.min(inds[:,2]), np.max(inds[:,3])]\n",
    "#         dg_inds = [int(i) for i in np.median(inds, axis=0)]\n",
    "\n",
    "        #Calculate coverage based on non-continuous alignments gap1+rri\n",
    "        chrom1,strand1,chrom2,strand2=tuple(genealign[0][1:3]+genealign[0][6:8])\n",
    "        start1,end1,start2,end2=tuple(dg_inds)\n",
    "#         range1=[i*10 for i in range(floor(int(start1)/10),ceil(int(end1)/10))]\n",
    "#         range2=[i*10 for i in range(floor(int(start2)/10),ceil(int(end2)/10))]\n",
    "#         overlap1=max([covdict[(chrom1,strand1,i)] for i in range1 if\n",
    "#                       (chrom1,strand1,i) in covdict])\n",
    "#         overlap2=max([covdict[(chrom2,strand2,i)] for i in range2 if\n",
    "#                       (chrom2,strand2,i) in covdict])\n",
    "#         covfrac=len(alignids)/np.sqrt(overlap1*overlap2)\n",
    "        #print(dg,len(alignids),overlap1,overlap2,covfrac)\n",
    "\n",
    "       \n",
    "        # Assign NG for compact visualization in genome browsers e.g. IGV\n",
    "        # ng_dict format: ng_id: [dg_id list]\n",
    "        # ng_dg_align format: list of DG ids.\n",
    "        # ng_dgs: list of dgs for each ng.\n",
    "        # DGs in each (gene1,gene2) pair are processed separately.\n",
    "        # To visualize alignments properly in IGV,\n",
    "        # set \"Sort alignments by tag DG\" and \"Group alignments by tag NG\"\n",
    "        if len(ng_dict)==0: ng_dict[ng_ind]=[dg]; dg_ng=ng_ind; ng_ind+=1\n",
    "        else:\n",
    "            ng_assigned = 0\n",
    "            for (ng, ng_dgs) in ng_dict.items():\n",
    "                ng_overlaps = np.zeros(len(ng_dgs))\n",
    "                for (i, ng_dg) in enumerate(ng_dgs):\n",
    "                    ng_dg_align = dict.fromkeys(dg_align_dict[ng_dg])\n",
    "                    dginfo=[i for i in genealign if i[0] in ng_dg_align]\n",
    "                    #dginfo: [[alignid,info1,info2]...].\n",
    "                    #info:chrom,strand,start,end,line\n",
    "                    ng_dg_min = min([i[3] for i in dginfo])\n",
    "                    ng_dg_max = max([i[9] for i in dginfo])\n",
    "                    overlap = min(dg_max, ng_dg_max) - max(dg_min, ng_dg_min)\n",
    "                    if overlap > 0: ng_overlaps[i] = 1\n",
    "                if sum(ng_overlaps) == 0:\n",
    "                    ng_dict[ng].append(dg); dg_ng = ng; ng_assigned += 1; break\n",
    "            if ng_assigned == 0:\n",
    "                ng_dict[ng_ind] = [dg]; dg_ng = ng_ind; ng_ind += 1\n",
    "        \n",
    "        dg_stats_dict[dg]={'chromstrand': [chrom1,strand1,chrom2,strand2],\n",
    "                           'dg_inds': dg_inds,\n",
    "                           'num_align': len(alignids), 'NG': dg_ng}\n",
    "    return dg_stats_dict\n",
    "\n",
    "def writedg(outdg,dg_stats_dict,genepair): #bedpe format output\n",
    "    \"\"\"\n",
    "    see bedpe definition here: \n",
    "    https://bedtools.readthedocs.io/en/latest/content/general-usage.html\n",
    "    chrom1 start1 end1 chrom2 start2 end2 name score strand1 strand2 additional\n",
    "    bedpe can be easily converted to the bed12 format to visualize arcs. \n",
    "    \"\"\"\n",
    "    with open(outdg, 'w+') as f:\n",
    "        for (dg, dg_info) in dg_stats_dict.items():\n",
    "            chromstrand,dg_inds = dg_info['chromstrand'],dg_info['dg_inds']\n",
    "            num_align = dg_info['num_align']\n",
    "            dg_str = '{0},{1},{2}'.format(genepair, dg, 0)\n",
    "            line = [chromstrand[0], str(dg_inds[0]), str(dg_inds[1]),\n",
    "                    chromstrand[2], str(dg_inds[2]), str(dg_inds[3]), dg_str, \n",
    "                    str(num_align), chromstrand[1], chromstrand[3]]\n",
    "            f.write('\\t'.join(line)+'\\n')\n",
    "    return\n",
    "\n",
    "def get_graph(test_lst, t=0.2):\n",
    "    '''\n",
    "    the different version of the function graph_align\n",
    "    format of test_lst\n",
    "    [[alignid,info1,info2]...]. info:chrom,strand,start,end,line for two strands\n",
    "    line can be anything\n",
    "    alignids: np array. Read IDs\n",
    "    '''\n",
    "    alignids = [i[0] for i in test_lst]\n",
    "    alignindsdict = dict([(i[0],i[3:5]+i[8:10]) for i in test_lst])\n",
    "\n",
    "    graph = nx.Graph()\n",
    "    alignindsdict_backup = {}\n",
    "    alignids = list(alignindsdict.keys())\n",
    "    # loop through the dictionary and discard the first kv pair in current dict after each iteration\n",
    "    pbar = tqdm(total = len(alignids))\n",
    "    while len(alignids)>0:\n",
    "        ID = alignids[0]\n",
    "    #     print(f'start with {ID}')\n",
    "        v_0 = alignindsdict[ID]\n",
    "        for k, v in alignindsdict.items():\n",
    "            if ID != k:\n",
    "                ratio_l, ratio_r = get_overlap_ratios(v_0, v)\n",
    "                if (ratio_l > t) and (ratio_r > t): \n",
    "                    graph.add_edge(ID, k, weight=(ratio_l + ratio_r))\n",
    "    #                 print(f'add edge {ID} and {k}')\n",
    "    #                 print(f'ratios are {ratio_l} and {ratio_r}')\n",
    "    #                 print(f'add edge {v_0} and {v}')\n",
    "        alignids.pop(0)\n",
    "        alignindsdict_backup[ID] = v\n",
    "        del alignindsdict[ID]\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e727d9-a848-408e-9997-5e687626a316",
   "metadata": {},
   "source": [
    "# Rewrite get_graph function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66e254d6-1ebc-4ef3-b53a-32de3332028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for node creation with multiprocessing\n",
    "def get_overlap_node_weight(i, filtered_df, t=0.8):\n",
    "    '''\n",
    "    function to generate connected nodes and weight in a graph\n",
    "    given a df (filtered_df) that contains pair information (gene1, start1, end1, gene2, start2, end2)\n",
    "    note the df should be reindexed, i is the index for each row\n",
    "    t is the overlapping threshold, if two pairs overalap>t, they are conected in the graph\n",
    "    out put is a list of index (ID, or nodes) that are considered overlapped -- overlap_ID\n",
    "    and the weight associated with the overlapped nodes\n",
    "    '''\n",
    "    # start and end positions of this row\n",
    "    start1, end1, start2, end2 = filtered_df.loc[i, ['start1', 'end1', 'start2', 'end2']]\n",
    "    # slice the df to only contain the rows after index i\n",
    "    df_to_compare = filtered_df[i+1:]\n",
    "    # change here to all other rows\n",
    "    # df_to_compare = filtered_df\n",
    "    # # now calculate the overlap ratio between the row and df_to_compare\n",
    "    mat_compare = df_to_compare[['start1', 'end1', 'start2', 'end2']].values\n",
    "    # stats for the current row\n",
    "    mat_current = np.tile([start1, end1, start2, end2], len(df_to_compare)).reshape(-1, 4)\n",
    "    # calculate min, max values based on the get_overlap_ratios function\n",
    "    min0, min1, min2, min3 = [np.minimum(mat_compare, mat_current)[:, i] for i in range(mat_current.shape[1])]\n",
    "    max0, max1, max2, max3 = [np.maximum(mat_compare, mat_current)[:, i] for i in range(mat_current.shape[1])]\n",
    "    ratio_l = (min1-max0+1) / (max1-min0+1)\n",
    "    ratio_r = (min3-max2+1) / (max3-min2+1)\n",
    "    # get index of entries that have overlapping ratio greater than t (0.7 here)\n",
    "    list1 = [index for index,v in enumerate(ratio_l) if v > t]\n",
    "    list2 = [index for index,v in enumerate(ratio_r) if v > t]\n",
    "    # note here j+i+1 is to correct the index in list1 and list2\n",
    "    # the starting index (0) in list1 and list2 is actually i+1 in the original filtered_df\n",
    "    # because the two lists are from df_to_compare, which is filtered_df[i+1:]\n",
    "    overlap_ID = [j+i+1 for j in list(set(list1).intersection(list2))]\n",
    "    # change here to all other rows\n",
    "    # overlap_ID = list(set(list1).intersection(list2))\n",
    "    weight = [ratio_l[num-i-1] + ratio_r[num-i-1] for num in overlap_ID]\n",
    "    # for num in overlap_ID:\n",
    "    #     graph.add_edge(i, num, weight=(ratio_l[num] + ratio_r[num]))\n",
    "    return overlap_ID, weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db656ca3-cf08-4064-8339-8cfa6be7a7ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_total_clustering(n, top_50_snoRNA, test_df, t, csv_name = 'dummy', \n",
    "                         ncore = 60, select = 'median', threshold = 20):\n",
    "    '''\n",
    "    function to generate a graph and run spectral clustering\n",
    "    n is the index in top_50_snoRNA (snoRNA df, at least contain snoRNA name as the \"name\" column)\n",
    "    test_df is the df contains pair information (gene1, start1, end1, gene2, start2, end2)\n",
    "    t is the overlapping threshold, if two pairs overalap>t, they are conected in the graph\n",
    "    csv_name is the output csv name\n",
    "    ncore is the number of cores used for multiprocessing\n",
    "    select is the way to pick data group a group, either median or minmax\n",
    "    threshold is the minimum number of counts\n",
    "    '''\n",
    "    # 0. select snoRNA\n",
    "    snoRNA = top_50_snoRNA.loc[n, 'name']\n",
    "    # https://stackoverflow.com/questions/5442910/how-to-use-multiprocessing-pool-map-with-multiple-arguments\n",
    "    # 1. generate graph parameters (IDs that are overlapped and the weight)\n",
    "    p = Pool(ncore)\n",
    "    print(f'processing {snoRNA}...')\n",
    "    filtered_df = test_df[(test_df['gene1'] == snoRNA)].reset_index()\n",
    "    filtered_df = filtered_df.rename(columns={'level_0':'ID'})\n",
    "    # generating graph parameters (connected nodes and weights)\n",
    "    result = p.starmap(get_overlap_node_weight, zip(np.arange(len(filtered_df)), \n",
    "                                                    repeat(filtered_df), repeat(t)))\n",
    "\n",
    "    # 2. create weighted graph\n",
    "    print('creating weighted graph...')\n",
    "    graph = nx.Graph()\n",
    "    for i, v in tqdm(enumerate(result), total = len(result)):\n",
    "        if v[0]:\n",
    "            for j, k in enumerate(v[0]):\n",
    "                graph.add_edge(i, k, weight=(v[1][j]))\n",
    "\n",
    "    # 3. spectral clustering\n",
    "    print('spectral clustering...')\n",
    "    sprctal_cluster = get_spectral(graph)\n",
    "\n",
    "    # 4. get dg dictionary \n",
    "    # in this dictionary, keys are the DG group numbers, values are the index in df that belong to this DG group\n",
    "    print('get DG dictionary...')\n",
    "    dg_align_dict = get_dgs(sprctal_cluster)\n",
    "\n",
    "    # 5. get groups df, save csv\n",
    "    # select rows in the filtered_df using indexes generated from clustering in the last step\n",
    "    print('get DG output...')\n",
    "    groups = []\n",
    "    for k, v in dg_align_dict.items():\n",
    "        group_df = filtered_df.loc[v]\n",
    "        if select == 'median':\n",
    "            start1, end1, start2, end2 = \\\n",
    "            np.median(group_df[['start1', 'end1', 'start2', 'end2']], axis = 0).astype(int)\n",
    "        if select == 'minmax':\n",
    "            start1, start2 = np.min(group_df[['start1', 'start2']], axis = 0).astype(int)\n",
    "            end1, end2 = np.max(group_df[['end1', 'end2']], axis = 0).astype(int)\n",
    "        if select == 'percentile':\n",
    "            start1, start2 = \\\n",
    "            np.percentile(group_df[['start1', 'start2']], 25, axis = 0).astype(int)\n",
    "            \n",
    "            end1, end2 = \\\n",
    "            np.percentile(group_df[['end1', 'end2']], 75, axis = 0).astype(int)\n",
    "        \n",
    "        count = len(group_df)\n",
    "        groups.append([start1, end1, start2, end2, count]) \n",
    "    output_df = pd.DataFrame(groups, columns = ['start1', 'end1', 'start2', 'end2', 'count'])\n",
    "    output_df.insert(0, column='snoRNA', value=snoRNA)\n",
    "    output_df.insert(3, column='target', value='45S_rRNA')\n",
    "    output_df = output_df.sort_values(by = 'count', ascending = False)\n",
    "    output_df = output_df[output_df['count']>=threshold]\n",
    "    output_df.to_csv(csv_name + '.csv', index = False)\n",
    "    \n",
    "    # terminate Pool\n",
    "    p.close()\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9d7298e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_total_clustering_nonsnoRNA(filtered_df, t, target_name1, target_name2,\n",
    "                                   csv_name = 'dummy', ncore = 60, \n",
    "                                   select = 'median', threshold = 20, save = True):\n",
    "    '''\n",
    "    function to generate a graph and run spectral clustering for non-snoRNA analysis\n",
    "    filtered_df is the df contains pair information (gene1, start1, end1, gene2, start2, end2)\n",
    "    t is the overlapping threshold, if two pairs overalap>t, they are conected in the graph\n",
    "    csv_name is the output csv name\n",
    "    ncore is the number of cores used for multiprocessing\n",
    "    select is the way to pick data group a group, either median or minmax\n",
    "    threshold is the minimum number of counts\n",
    "    target_name1, target_name2 are the names of RNAs that interact\n",
    "    '''\n",
    "    # https://stackoverflow.com/questions/5442910/how-to-use-multiprocessing-pool-map-with-multiple-arguments\n",
    "    # 1. generate graph parameters (IDs that are overlapped and the weight)\n",
    "    p = Pool(ncore)\n",
    "    print(f'processing...')\n",
    "    # generating graph parameters (connected nodes and weights)\n",
    "    result = p.starmap(get_overlap_node_weight, zip(np.arange(len(filtered_df)), \n",
    "                                                    repeat(filtered_df), repeat(t)))\n",
    "\n",
    "    # 2. create weighted graph\n",
    "    print('creating weighted graph...')\n",
    "    graph = nx.Graph()\n",
    "    for i, v in tqdm(enumerate(result), total = len(result)):\n",
    "        if v[0]:\n",
    "            for j, k in enumerate(v[0]):\n",
    "                graph.add_edge(i, k, weight=(v[1][j]))\n",
    "\n",
    "    # 3. spectral clustering\n",
    "    print('spectral clustering...')\n",
    "    sprctal_cluster = get_spectral(graph)\n",
    "\n",
    "    # 4. get dg dictionary \n",
    "    # in this dictionary, keys are the DG group numbers, values are the index in df that belong to this DG group\n",
    "    print('get DG dictionary...')\n",
    "    dg_align_dict = get_dgs(sprctal_cluster)\n",
    "    \n",
    "    # skip empty dict\n",
    "    if dg_align_dict == {}:\n",
    "        return None\n",
    "\n",
    "    # 5. get groups df, save csv\n",
    "    # select rows in the filtered_df using indexes generated from clustering in the last step\n",
    "    print('get DG output...')\n",
    "    dct = defaultdict(int)\n",
    "    for k, v in dg_align_dict.items():\n",
    "        group_df = filtered_df.loc[v]\n",
    "        if select == 'median':\n",
    "            start1, end1, start2, end2 = \\\n",
    "            np.median(group_df[['start1', 'end1', 'start2', 'end2']], axis = 0).astype(int)\n",
    "        if select == 'minmax':\n",
    "            start1, start2 = np.min(group_df[['start1', 'start2']], axis = 0).astype(int)\n",
    "            end1, end2 = np.max(group_df[['end1', 'end2']], axis = 0).astype(int)\n",
    "        if select == 'percentile':\n",
    "            start1, start2 = \\\n",
    "            np.percentile(group_df[['start1', 'start2']], 25, axis = 0).astype(int)\n",
    "            \n",
    "            end1, end2 = \\\n",
    "            np.percentile(group_df[['end1', 'end2']], 75, axis = 0).astype(int)\n",
    "        \n",
    "        count = len(group_df)\n",
    "        string = ('_').join([str(start1), str(end1), str(start2), str(end2)])\n",
    "        dct[string] += count\n",
    "    \n",
    "    # make data frame\n",
    "    dct_df = pd.DataFrame(dct.items())\n",
    "    output_df = dct_df[0].str.split('_', expand = True)\n",
    "    output_df[4]= dct_df[1]\n",
    "    output_df.columns = ['start1', 'end1', 'start2', 'end2', 'count']\n",
    "    output_df.insert(0, column='gene1', value=target_name1)\n",
    "    output_df.insert(3, column='gene2', value=target_name2)\n",
    "    output_df = output_df.sort_values(by = 'count', ascending = False)\n",
    "    output_df = output_df[output_df['count']>=threshold]\n",
    "    if save:\n",
    "        output_df.to_csv(csv_name + '.csv', index = False)\n",
    "    \n",
    "    # terminate Pool\n",
    "    p.close()\n",
    "    p.join()\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54b96e7-e68c-446b-94ca-2bafe191a4f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
